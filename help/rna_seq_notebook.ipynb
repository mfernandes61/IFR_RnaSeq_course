{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Introduction to RNA-seq Data Analysis\n",
      "(Myrto Kostadima) RNA Sequencing Analysis Workshop\n",
      "( University of Cambridge November, 2016) \n",
      "## 1. General information <br>\n",
      "<b>Resources used</b> <br>\n",
      "Tophat: http://ccb.jhu.edu/software/tophat/index.shtml <br>\n",
      "Cufflinks: http://cole-trapnell-lab.github.io/cufflinks/ <br>\n",
      "Samtools: http://samtools.sourceforge.net/ <br>\n",
      "IGV genome browser: http://www.broadinstitute.org/igv/ <br>\n",
      "Ensembl genome browser: http://www.ensembl.org/ <br>\n",
      "HTSeq-count: http://www-huber.embl.de/users/anders/HTSeq/doc/count.html <br>\n",
      "DESeq2: http://bioconductor.org/packages/release/bioc/html/DESeq2.html <br>\n",
      "DEXSeq: http://bioconductor.org/packages/release/bioc/html/DEXSeq.html <br>\n",
      "STAR: https://github.com/alexdobin/STAR <br>\n",
      "Original data can be found here: http://www.ebi.ac.uk/ena/data/view/ERA015179 <br>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2 Introduction\n",
      "The goal of this hands-on session is to perform some basic tasks in the downstream\n",
      "analysis of RNA-seq data. We will start from RNA-seq data aligned to the zebrafish\n",
      "genome using Tophat. We will perform transcriptome reconstruction using Cufflinks\n",
      "and we will compare the gene expression between two different conditions in order to\n",
      "identify differentially expressed genes using Cuffdiff.   \n",
      "\n",
      "<u><b>Prepare environment</b></u><br>\n",
      "We will use a dataset derived from sequencing of mRNA from Danio rerio embryos in\n",
      "two different developmental stages. Sequencing was performed on the Illumina platform\n",
      "and generated 76bp paired-end sequence data using poly-(A)+ selected RNA.    \n",
      "Due to the time constraints of the practical we will only use a subset of the reads.\n",
      "The data files are contained in the subdirectory called data and are the following:\n",
      "\u2022 2cells_1.fastq and 2cells_2.fastq: these files are based on RNA-seq data\n",
      "of a 2-cell zebrafish embryo, and\n",
      "\u2022 6h_1.fastq and 6h_2.fastq: these files are based on RNA-seq data of zebrafish\n",
      "embryos 6h post fertilisation."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ensure that you have mapped /coursedata to a local folder within kitematic and copied /course_material to it.   \n",
      "Check that the data folder contains the above-mentioned files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! reveal_answer 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cp -R /course_material /Coursedata\r\n",
        "cd /Coursedata\r\n",
        "ls -l data\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Coursedata\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<u><b>Alignment</b></u><br>\n",
      "There are numerous tools performing short read alignment and the choice of aligner\n",
      "should be carefully made according to the analysis goals/requirements. Here we will\n",
      "use <B>Tophat</b>, a widely used ultrafast aligner that performs spliced alignments. <a href=\"https://ccb.jhu.edu/software/tophat/index.shtml\">Tophat</A> is\n",
      "based on <a href=\"http://bowtie-bio.sourceforge.net/index.shtml\">Bowtie</a> (a splice-unaware aligner) to perform alignments and uses an indexed\n",
      "genome to keep its memory footprint small and the running time short.   \n",
      "(Note: Tophat whilst still frequently used has been superceded by another John Hopkins University  program called <a href=\"http://ccb.jhu.edu/software/hisat2/index.shtml\">HISAT2</a>).  \n",
      "Because of time constraints we will build the index only for one chromosome of the zebrafish genome.<br>\n",
      "\n",
      "For this we need the chromosome sequence in fasta format. This is stored in a file\n",
      "named Danio_rerio.Zv9.66.dna.fa, under the subdirectory genome.   \n",
      "The command to use is <u><b>bowtie-build</b> {path_to_genome/genomefile} {path_to_genome/output_files_prefix}</u>   \n",
      "Throughout this material we are assuming that the prefix is ZV9. If you choose something else, modify \n",
      "the example commands appropriately.    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! reveal_answer 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Create the indexed genome using the following command:\r\n",
        "bowtie2-build genome/Danio_rerio.Zv9.66.dna.fa genome/ZV9\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! bowtie2-build genome/Danio_rerio.Zv9.66.dna.fa genome/ZV9\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Settings:\r\n",
        "  Output files: \"genome/ZV9.*.bt2\"\r\n",
        "  Line rate: 6 (line is 64 bytes)\r\n",
        "  Lines per side: 1 (side is 64 bytes)\r\n",
        "  Offset rate: 4 (one in 16)\r\n",
        "  FTable chars: 10\r\n",
        "  Strings: unpacked\r\n",
        "  Max bucket size: default\r\n",
        "  Max bucket size, sqrt multiplier: default\r\n",
        "  Max bucket size, len divisor: 4\r\n",
        "  Difference-cover sample period: 1024\r\n",
        "  Endianness: little\r\n",
        "  Actual local endianness: little\r\n",
        "  Sanity checking: disabled\r\n",
        "  Assertions: disabled\r\n",
        "  Random seed: 0\r\n",
        "  Sizeofs: void*:8, int:4, long:8, size_t:8\r\n",
        "Input files DNA, FASTA:\r\n",
        "  genome/Danio_rerio.Zv9.66.dna.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading reference sizes\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Time reading reference sizes: 00:00:00\r\n",
        "Calculating joined length\r\n",
        "Writing header\r\n",
        "Reserving space for joined string\r\n",
        "Joining reference sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Time to join reference sequences: 00:00:01\r\n",
        "bmax according to bmaxDivN setting: 12640127\r\n",
        "Using parameters --bmax 9480096 --dcv 1024\r\n",
        "  Doing ahead-of-time memory usage test\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Passed!  Constructing with these parameters: --bmax 9480096 --dcv 1024\r\n",
        "Constructing suffix-array element generator\r\n",
        "Building DifferenceCoverSample\r\n",
        "  Building sPrime\r\n",
        "  Building sPrimeOrder\r\n",
        "  V-Sorting samples\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  V-Sorting samples time: 00:00:03\r\n",
        "  Allocating rank array\r\n",
        "  Ranking v-sort output\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Ranking v-sort output time: 00:00:00\r\n",
        "  Invoking Larsson-Sadakane on ranks\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Invoking Larsson-Sadakane on ranks time: 00:00:01\r\n",
        "  Sanity-checking and returning\r\n",
        "Building samples\r\n",
        "Reserving space for 12 sample suffixes\r\n",
        "Generating random suffixes\r\n",
        "QSorting 12 sample offsets, eliminating duplicates\r\n",
        "QSorting sample offsets, eliminating duplicates time: 00:00:00\r\n",
        "Multikey QSorting 12 samples\r\n",
        "  (Using difference cover)\r\n",
        "  Multikey QSorting samples time: 00:00:00\r\n",
        "Calculating bucket sizes\r\n",
        "  Binary sorting into buckets\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:04\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Split 1, merged 5; iterating...\r\n",
        "  Binary sorting into buckets\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:02\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Avg bucket size: 6.32006e+06 (target: 9480095)\r\n",
        "Converting suffix-array elements to index image\r\n",
        "Allocating ftab, absorbFtab\r\n",
        "Entering Ebwt loop\r\n",
        "Getting block 1 of 8\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 6990931\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:05\r\n",
        "Returning block of 6990932\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 2 of 8\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 4417400\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:03\r\n",
        "Returning block of 4417401\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 3 of 8\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 6291642\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:04\r\n",
        "Returning block of 6291643\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 4 of 8\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:02\r\n",
        "  Sorting block of length 7533629\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:03\r\n",
        "Returning block of 7533630\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 5 of 8\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 7160010\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:03\r\n",
        "Returning block of 7160011\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 6 of 8\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 5101612\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:02\r\n",
        "Returning block of 5101613\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 7 of 8\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:02\r\n",
        "  Sorting block of length 8951274\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:06\r\n",
        "Returning block of 8951275\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 8 of 8\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:02\r\n",
        "  Sorting block of length 4114003\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:02\r\n",
        "Returning block of 4114004\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Exited Ebwt loop\r\n",
        "fchr[A]: 0\r\n",
        "fchr[C]: 16076836\r\n",
        "fchr[G]: 25225277\r\n",
        "fchr[T]: 34418920\r\n",
        "fchr[$]: 50560508\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Exiting Ebwt::buildToDisk()\r\n",
        "Returning from initFromVector\r\n",
        "Wrote 21065730 bytes to primary EBWT file: genome/ZV9.1.bt2\r\n",
        "Wrote 12640132 bytes to secondary EBWT file: genome/ZV9.2.bt2\r\n",
        "Re-opening _in1 and _in2 as input streams\r\n",
        "Returning from Ebwt constructor\r\n",
        "Headers:\r\n",
        "    len: 50560508\r\n",
        "    bwtLen: 50560509\r\n",
        "    sz: 12640127\r\n",
        "    bwtSz: 12640128\r\n",
        "    lineRate: 6\r\n",
        "    offRate: 4\r\n",
        "    offMask: 0xfffffff0\r\n",
        "    ftabChars: 10\r\n",
        "    eftabLen: 20\r\n",
        "    eftabSz: 80\r\n",
        "    ftabLen: 1048577\r\n",
        "    ftabSz: 4194308\r\n",
        "    offsLen: 3160032\r\n",
        "    offsSz: 12640128\r\n",
        "    lineSz: 64\r\n",
        "    sideSz: 64\r\n",
        "    sideBwtSz: 48\r\n",
        "    sideBwtLen: 192\r\n",
        "    numSides: 263336\r\n",
        "    numLines: 263336\r\n",
        "    ebwtTotLen: 16853504\r\n",
        "    ebwtTotSz: 16853504\r\n",
        "    color: 0\r\n",
        "    reverse: 0\r\n",
        "Total time for call to driver() for forward index: 00:00:58\r\n",
        "Reading reference sizes\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Time reading reference sizes: 00:00:01\r\n",
        "Calculating joined length\r\n",
        "Writing header\r\n",
        "Reserving space for joined string\r\n",
        "Joining reference sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Time to join reference sequences: 00:00:01\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Time to reverse reference sequence: 00:00:00\r\n",
        "bmax according to bmaxDivN setting: 12640127\r\n",
        "Using parameters --bmax 9480096 --dcv 1024\r\n",
        "  Doing ahead-of-time memory usage test\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Passed!  Constructing with these parameters: --bmax 9480096 --dcv 1024\r\n",
        "Constructing suffix-array element generator\r\n",
        "Building DifferenceCoverSample\r\n",
        "  Building sPrime\r\n",
        "  Building sPrimeOrder\r\n",
        "  V-Sorting samples\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  V-Sorting samples time: 00:00:01\r\n",
        "  Allocating rank array\r\n",
        "  Ranking v-sort output\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Ranking v-sort output time: 00:00:01\r\n",
        "  Invoking Larsson-Sadakane on ranks\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Invoking Larsson-Sadakane on ranks time: 00:00:00\r\n",
        "  Sanity-checking and returning\r\n",
        "Building samples\r\n",
        "Reserving space for 12 sample suffixes\r\n",
        "Generating random suffixes\r\n",
        "QSorting 12 sample offsets, eliminating duplicates\r\n",
        "QSorting sample offsets, eliminating duplicates time: 00:00:00\r\n",
        "Multikey QSorting 12 samples\r\n",
        "  (Using difference cover)\r\n",
        "  Multikey QSorting samples time: 00:00:00\r\n",
        "Calculating bucket sizes\r\n",
        "  Binary sorting into buckets\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:04\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Split 1, merged 6; iterating...\r\n",
        "  Binary sorting into buckets\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:03\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Split 1, merged 0; iterating...\r\n",
        "  Binary sorting into buckets\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:02\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Split 1, merged 1; iterating...\r\n",
        "  Binary sorting into buckets\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:02\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Split 1, merged 1; iterating...\r\n",
        "  Binary sorting into buckets\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:02\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Avg bucket size: 5.61783e+06 (target: 9480095)\r\n",
        "Converting suffix-array elements to index image\r\n",
        "Allocating ftab, absorbFtab\r\n",
        "Entering Ebwt loop\r\n",
        "Getting block 1 of 9\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 1679233\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 1679234\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 2 of 9\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 9151529\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:04\r\n",
        "Returning block of 9151530\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 3 of 9\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 5246071\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:02\r\n",
        "Returning block of 5246072\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 4 of 9\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 6795889\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:02\r\n",
        "Returning block of 6795890\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 5 of 9\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 3198791\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:02\r\n",
        "Returning block of 3198792\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 6 of 9\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 6632648\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:03\r\n",
        "Returning block of 6632649\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 7 of 9\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 6698263\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:02\r\n",
        "Returning block of 6698264\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 8 of 9\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 5533068\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:03\r\n",
        "Returning block of 5533069\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 9 of 9\r\n",
        "  Reserving size (9480096) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:01\r\n",
        "  Sorting block of length 5625008\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:02\r\n",
        "Returning block of 5625009\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Exited Ebwt loop\r\n",
        "fchr[A]: 0\r\n",
        "fchr[C]: 16076836\r\n",
        "fchr[G]: 25225277\r\n",
        "fchr[T]: 34418920\r\n",
        "fchr[$]: 50560508\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Exiting Ebwt::buildToDisk()\r\n",
        "Returning from initFromVector\r\n",
        "Wrote 21065730 bytes to primary EBWT file: genome/ZV9.rev.1.bt2\r\n",
        "Wrote 12640132 bytes to secondary EBWT file: genome/ZV9.rev.2.bt2\r\n",
        "Re-opening _in1 and _in2 as input streams\r\n",
        "Returning from Ebwt constructor\r\n",
        "Headers:\r\n",
        "    len: 50560508\r\n",
        "    bwtLen: 50560509\r\n",
        "    sz: 12640127\r\n",
        "    bwtSz: 12640128\r\n",
        "    lineRate: 6\r\n",
        "    offRate: 4\r\n",
        "    offMask: 0xfffffff0\r\n",
        "    ftabChars: 10\r\n",
        "    eftabLen: 20\r\n",
        "    eftabSz: 80\r\n",
        "    ftabLen: 1048577\r\n",
        "    ftabSz: 4194308\r\n",
        "    offsLen: 3160032\r\n",
        "    offsSz: 12640128\r\n",
        "    lineSz: 64\r\n",
        "    sideSz: 64\r\n",
        "    sideBwtSz: 48\r\n",
        "    sideBwtLen: 192\r\n",
        "    numSides: 263336\r\n",
        "    numLines: 263336\r\n",
        "    ebwtTotLen: 16853504\r\n",
        "    ebwtTotSz: 16853504\r\n",
        "    color: 0\r\n",
        "    reverse: 1\r\n",
        "Total time for backward call to driver() for mirror index: 00:00:52\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This command will output 6 files that constitute the index. These files that have\n",
      "the prefix ZV9 are stored in the genome subdirectory. Check that the files have been\n",
      "successfully created."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! reveal_answer 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ls -l genome\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ls -l genome"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 128525\r\n",
        "-rwxrwxrwx 1 ubuntu staff 51542283 Mar  8 16:13 Danio_rerio.Zv9.66.dna.fa\r\n",
        "-rwxrwxrwx 1 ubuntu staff 21065730 Mar  8 16:43 ZV9.1.bt2\r\n",
        "-rwxrwxrwx 1 ubuntu staff 12640132 Mar  8 16:43 ZV9.2.bt2\r\n",
        "-rwxrwxrwx 1 ubuntu staff    13301 Mar  8 16:42 ZV9.3.bt2\r\n",
        "-rwxrwxrwx 1 ubuntu staff 12640127 Mar  8 16:42 ZV9.4.bt2\r\n",
        "-rwxrwxrwx 1 ubuntu staff 21065730 Mar  8 16:44 ZV9.rev.1.bt2\r\n",
        "-rwxrwxrwx 1 ubuntu staff 12640132 Mar  8 16:44 ZV9.rev.2.bt2\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the genome is indexed we can move on to the actual alignment. Tophat has\n",
      "a number of parameters in order to perform the alignment. To view them all type\n",
      "<b>tophat --help</b>    \n",
      "The general format of the tophat command is:\n",
      "tophat [options]* {index_base} {reads_1} {reads_2}\n",
      "Where the last two arguments are the .fastq files of the paired end reads, and the\n",
      "argument before is the basename of the indexed genome.\n",
      "Some parameters that we are going to use to run Tophat are listed below:\n",
      "-g maximum number of multihits allowed. Short reads are likely to map to\n",
      "more than one locations in the genome even though these reads can\n",
      "have originated from only one of these regions. In RNA-seq we allow\n",
      "for a restricted number of multihits, and in this case we ask Tophat\n",
      "to report only reads that map at most onto 2 different loci.\n",
      "-p use these many threads to align reads\n",
      "--library-type before performing any type of RNA-seq analysis you need\n",
      "to know a few things about the library preparation. Was it done using\n",
      "a strand-specific protocol or not? If yes, which strand? In our data\n",
      "the protocol was NOT strand specific.\n",
      "-j improve spliced alignment by providing *Tophat* with annotated splice\n",
      "junctions. Pre-existing genome annotation is an advantage when\n",
      "analysing RNA-seq data. This file contains the coordinates of\n",
      "annotated splice junctions from Ensembl. These are stored under the\n",
      "sub-directory annotation in a file called `ZV9.spliceSites`.\n",
      "-o this specifies in which subdirectory *Tophat* should save the output\n",
      "files.   Given that for every run the name of the output files is the\n",
      "same, we specify different folders for each run.\n",
      "Now we will proceed with the alignment of the paired-end data for the two different\n",
      "conditions. Due to the fact that the spliced alignment takes long even for a subset of\n",
      "the reads, we will only align one of the two datasets. The other one has been already\n",
      "aligned for you.\n",
      "Question 1.   \n",
      "Given that we used the following command to align the 2cells dataset:   \n",
      "<b>tophat --solexa-quals -g 2 -p 4 --library-type fr-unstranded -j\n",
      "annotation/Danio_rerio.Zv9.66.spliceSites -o tophat/ZV9_2cells   \n",
      " genome/ZV9 data/2cells_1.fastq data/2cells_2.fastq</b>   \n",
      "What is the command required to align the \u20186h\u2019 dataset? Run this command on the\n",
      "terminal.\n",
      "Note: You will have to change the input fastq files and the output folder. If you don\u2019t\n",
      "change the output folder, then these results will overwrite the ones for the 2cells\n",
      "dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! reveal_answer 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tophat --solexa-quals -g 2 -p 4 --library-type fr-unstranded \\\r\n",
        "-j annotation/Danio_rerio.Zv9.66.spliceSites -o tophat/ZV9_2cells  \\\r\n",
        "genome/ZV9 data/2cells_1.fastq data/2cells_2.fastq\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The alignment will take approximately 5 minutes. In the meantime please move on\n",
      "with the practical and we will get back to the terminal once the alignment is done.\n",
      "We will firstly look at some of the files produced by Tophat. For this please open the\n",
      "RNA-seq folder which can be found on your /home/participant/Desktop. Click on\n",
      "the tophat subfolder and then on the folder called ZV9_2cells.\n",
      "Tophat reports the alignments in a BAM file called <i>accepted_hits.bam</i>. Among others\n",
      "it also creates a <i>junctions.bed</i> files that stores the coordinates of the splice junctions\n",
      "present in your dataset, as these have been extracted from the spliced alignments.\n",
      "Now we will load the BAM file and the splice junctions onto IGV to visualise the\n",
      "alignments reported by Tophat.\n",
      "In order to launch IGV type in the next Notebook code field:      \n",
      "<b>igv </b> (NB you would type igv & if we were doing this in a command-line terminal - why?)   \n",
      "Ignore any warnings and when it opens you have to load the genome of interest.\n",
      "On the top left of your screen choose from the drop down menu Zebrafish (Zv9). Then\n",
      "in order to load the desire files go to:   \n",
      "File \u2013> Load from File  \n",
      "On the pop up window navigate to home \u2013> participant \u2013> Desktop   \n",
      "\u2013> RNA-seq \u2013> tophat \u2013> ZV9_2cells folder and select the file <i>accepted_hits.sorted.bam</i>.       \n",
      "Once the file is loaded right-click on the name of the track on the left and choose   \n",
      "Rename Track. Give the track a meaningful name.      \n",
      "Follow the same steps in order to load the <i>junctions.bed</i> file from the same folder.\n",
      "Finally following the same process load the Ensembl annotation <i>Danio_rerio.Zv9.66.gtf</i>\n",
      "stored under folder <i>annotation</i> under the RNA-seq folder.   \n",
      "On the top middle box you can specify the region you want your browser to zoom.\n",
      "Type chr12:20,270,921- 20,300,943.   \n",
      "Right-click on the name of the Ensembl track and choose Expanded.      \n",
      "<br>\n",
      "Questions\n",
      "1. Can you identify the splice junctions from the BAM file?     \n",
      "2. Are the junctions annotated for CBY1 consistent with the annotation?    \n",
      "3. Are all annotated genes (both from RefSeq and Ensembl) expressed?   \n",
      "Once you are done with the questions above, please close IGV.   \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Note that in order to load a BAM file onto IGV we need to have this file   \n",
      "sorted by genomic location and indexed. Here\u2019s a reminder of   \n",
      "the commands to perform these:    \n",
      "Sort the BAM file using samtools:   \n",
      "<b>samtools sort {bam file to be sorted} -o {output file name}</b>   \n",
      "Index the sorted file.   \n",
      "<b>samtools index {sorted bam file}</b>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once Tophat finishes running, sort the output.bam file and then index the sorted.bam\n",
      "file using the information above to guide you.\n",
      "Launch IGV again. This time we will change the configuration of IGV as described\n",
      "below. Go to:    \n",
      "View \u2013> Preferences\n",
      "Click on the tab Alignments and further down on the window tick the option Show\n",
      "junction track. Then type 5 in the box of the Min junction coverage. Click OK.\n",
      "Finally, load the alignments for the two datasets onto IGV following the steps described\n",
      "above. Please, load the Ensembl annotation as well."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b><u>Isoform expression and transcriptome assembly</u></b>   \n",
      "There are a number of tools that perform reconstruction of the transcriptome and for\n",
      "this workshop we are going to use <b>Cufflinks</b>. Cufflinks can do transcriptome assembly\n",
      "either ab initio or using a reference annotation. It also quantifies the isoform expression\n",
      "in FPKMs (Fragments Per Kilobase of exon per Million fragments mapped).   \n",
      "Cufflinks has a number of parameters in order to perform transcriptome assembly and\n",
      "quantification. To view them all type cufflinks --help   \n",
      "We aim to reconstruct the transcriptome for both samples by using the Ensembl annotation\n",
      "both strictly and as a guide. In the first case Cufflinks will only report isoforms\n",
      "that are included in the annotation, while in the latter case it will report novel isoforms\n",
      "as well.   \n",
      "The annotation from Ensembl of Danio rerio is stored under the folder annotation in\n",
      "a file called <i>Danio_rerio.Zv9.66.gtf</i>.   \n",
      "\n",
      "The general format of the cufflinks command is:   \n",
      "cufflinks [options] {aligned_reads.(sam/bam)}\n",
      "Where the input is the aligned reads (either in SAM or BAM format).\n",
      "Some of available parameters of Cufflinks that we are going to use to run Cufflinks are\n",
      "listed below:\n",
      "-o output directory   \n",
      "-G tells Cufflinks to use the supplied annotation strictly in order to\n",
      "estimate isoform annotation.   \n",
      "-b instructs Cufflinks to run a bias detection and correction    \n",
      "algorithm which can significantly improve accuracy of transcript \n",
      "abundance estimates. To do this *Cufflinks* requires a multi-fasta\n",
      "file with the genomic sequences against which we have aligned the\n",
      "reads.   \n",
      "-u tells Cufflinks to do an initial estimation procedure to more\n",
      "accurately weight reads mapping to multiple locations in the genome\n",
      "(multi-hits).    \n",
      "--library-type see Tophat parameters.    \n",
      "-p see Tophat parameters.   \n",
      "In the Notebook field below type:   \n",
      "<b>cufflinks -o cufflinks/ZV9_2cells_gff -G annotation/Danio_rerio.Zv9.66.gtf \\   \n",
      "-p 8 -b genome/Danio_rerio.Zv9.66.dna.fa -u --library-type fr-unstranded \\   \n",
      "tophat/ZV9_2cells/accepted_hits.bam</b>   \n",
      "\n",
      "(pre-fixed by the obligatory '!' to allow Ipython notebook to run the command)   "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Questions:    \n",
      "1. Given the previous command for 2cells dataset, how would you run Cufflinks\n",
      "for the other dataset 6h?    \n",
      "Run this command in the next Notebook code field.    \n",
      "Don\u2019t forget to change the output folder as the second command will overwrite the\n",
      "results of the previous run.   \n",
      "Take a look at the output folders that have been created. The results from    \n",
      "Cufflinks are stored in 4 different files named:   \n",
      "\u2022 genes.fpkm_tracking    \n",
      "\u2022 isoforms.fpkm_tracking    \n",
      "\u2022 skipped.gtf   \n",
      "\u2022 transcripts.gtf   \n",
      "Here\u2019s a short description of these files:   \n",
      "\u2022 genes.fpkm_tracking: contains the estimated gene-level expression values.   \n",
      "\u2022 isoforms.fpkm_tracking: contains the estimated isoform-level expression values.   \n",
      "\u2022 transcripts.gtf: This GTF file contains Cufflinks assembled isoforms   \n",
      "\n",
      "The complete documentation can be found at:   \n",
      "http://cole-trapnell-lab.github.io/cufflinks/cufflinks/#cufflinks-output-files   \n",
      "\n",
      "Now in order to perform guided transcriptome assembly (A transcriptome assembly that   \n",
      "reports novel transcripts as well) we will have to change the -G option of the    \n",
      "previous command.   \n",
      "In its place we will use the -g option that tells Cufflinks to assemble the   \n",
      "transcriptome using the supplied annotation as a guide and allowing for novel   \n",
      "transcripts.   \n",
      "\n",
      "Questions   \n",
      "Due to time constraints, please do not run the command for guided transcriptome   \n",
      "analysis. Instead, write the cufflinks command you would use to perform a guided   \n",
      "transcriptome assembly for the 2cells dataset in the space below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Performing the guided transcriptome analysis for the 2cells and 6h data sets would\n",
      "take 15-20min each. Therefore, we have pre-computed these for you and have the\n",
      "results under subdirectories: cufflinks/ZV9_2cells and cufflinks/ZV9_6h.\n",
      "Go back to the IGV browser and load the file transcripts.gtf which is located in the\n",
      "subdirectory cufflinks/ZV9_2cells/. Rename the track into something meaningful.\n",
      "This file contains the transcripts that Cufflinks assembled based on the alignment of\n",
      "our reads onto the genome.   \n",
      "Questions:   \n",
      "In the search box type ENSDART00000082297 in order for the browser to zoom in to\n",
      "the gene of interest. Compare between the already annotated transcripts and the ones\n",
      "assembled by Cufflinks. Do you observe any difference?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b><u>Differential Expression</u></b>   \n",
      "One of the stand-alone tools that perform differential expression analysis is Cuffdiff.\n",
      "We use this tool to compare between two conditions; for example different conditions\n",
      "could be control and disease, or wild-type and mutant, or various developmental stages.\n",
      "In our case we want to identify genes that are differentially expressed between two\n",
      "developmental stages; a 2 cell embryo and 6h post fertilization.\n",
      "The general format of the cuffdiff command is:\n",
      "cuffdiff [options] {transcripts.gtf}\n",
      "{sample1_replicate1.sam[,...,sample1_replicateM]}\n",
      "{sample2_replicate1.sam[,...,sample2_replicateM.sam]}\n",
      "Where the input includes a transcripts.gtf file, which is an annotation file of the\n",
      "genome of interest, and the aligned reads (either in SAM or BAM format) for the\n",
      "conditions.\n",
      "Some of the Cufflinks options that we will use to run the program are:    \n",
      "-o output directory,    \n",
      "-L labels for the different conditions,   \n",
      "-T tells *Cuffdiff* that the reads are from a time series experiment,   \n",
      "-b, -u, --library-type: same as above in Cufflinks.   \n",
      "\n",
      "To run cufdiff type on the terminal type:\n",
      "cuffdiff -o cuffdiff/ -L ZV9_2cells,ZV9_6h -T -b\n",
      "genome/Danio_rerio.Zv9.66.dna.fa -u --library-type fr-unstranded\n",
      "annotation/Danio_rerio.Zv9.66.gtf tophat/ZV9_2cells/accepted_hits.bam\n",
      "tophat/ZV9_6h/accepted_hits.bam   \n",
      "\n",
      "In the command above we have assumed that the folder where you stored\n",
      "the results of Tophat for dataset 6h was named ZV9_6h. If this is not the\n",
      "case please change the previous command accordingly otherwise you will\n",
      "get an error.    \n",
      "We are interested in the differential expression at the gene level. The results are\n",
      "reported by Cuffdiff in the file cuffdiff/gene_exp.diff.\n",
      "Look at the first few lines of the file using the following command:\n",
      "head -n 20 cuffdiff/gene_exp.diff\n",
      "We would like to see which are the most significantly differentially expressed\n",
      "genes. Therefore we will sort the above file according to the q value (corrected\n",
      "p value for multiple testing). The result will be stored in a different file called\n",
      "gene_exp_qval.sorted.diff.\n",
      "sort -t$'\\t' -g -k 13 cuffdiff/gene_exp.diff >\n",
      "cuffdiff/gene_exp_qval.sorted.diff\n",
      "Look again at the first few lines of the sorted file by typing:\n",
      "head -n 20 cuffdiff/gene_exp_qval.sorted.diff\n",
      "Copy the Ensembl identifier of one of these genes. Now go back to the IGV browser\n",
      "and paste it in the search box. Look at the raw aligned data for the two datasets.\n",
      "Questions\n",
      "Do you see any difference in the gene coverage between the two conditions that would\n",
      "justify that this gene has been called as differentially expressed?\n",
      "Note that the coverage on the Ensembl browser is based on raw reads and\n",
      "no normalisation has taken place contrary to the FPKM values."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b><u>Functional Annotation of Differentially Expressed\n",
      "genes</u></b>   \n",
      "After you have performed the differential expression analysis you are interested in\n",
      "identifying if there is any functionality enrichment for your differentially expressed\n",
      "genes.\n",
      "Open a web browser and go to the following URL http://david.abcc.ncifcrf.gov/\n",
      "On the left side click on Functional Annotation. Then click on the Upload tab. Under\n",
      "the section Choose from File, click Choose File and navigate to the cuffdiff\n",
      "folder. Select the file called globalDiffExprs_Genes_qval.01_top100.tab. Under\n",
      "Step 2 select ENSEMBL_GENE_ID from the drop-down menu. Finally select Gene\n",
      "List and then press Submit List.\n",
      "Click on Gene Ontology and then click on the CHART button of the GOTERM_BP_ALL\n",
      "item.\n",
      "Questions\n",
      "Do these categories make sense given the samples we\u2019re studying?\n",
      "Browse around DAVID website and check what other information are available.\n",
      "CONGRATULATIONS! You\u2019ve made it to the end of the practical.\n",
      "We hope you enjoyed it!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b><u>Bonus Exercise I</u></b>   \n",
      "During the alignment step of the practical you set the -j parameter to a file that\n",
      "contains all the annotated splice junctions. How can we generate this file for the\n",
      "mouse genome?\n",
      "\u2022 Google ensembl mouse GTF, go to FTP Download - Ensembl and then download\n",
      "the gene annotation file (GTF format) for the mouse genome. Hint: Please do\n",
      "NOT download the abinitio GTF file.\n",
      "\u2022 Store it under the RNA-seq/annotation folder\n",
      "11\n",
      "\u2022 Decompress the GTF file using gzip -d followed by the GTF file\n",
      "\u2022 Use the gtf_juncs command to extract the splice junctions from the decompressed\n",
      "GTF file and store the output under the annotation folder in a file called:\n",
      "mouse.juncs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bonus Exercise II - Read mapping with STAR\n",
      "STAR is a new aligner for RNA-seq, described here: https://github.com/alexdobin/\n",
      "STAR/\n",
      "The software is already installed on your computers.\n",
      "The documentation for STAR is available here: https://github.com/alexdobin/STAR/\n",
      "raw/master/doc/STARmanual.pdf\n",
      "As with Tophat, we first need to index the reference genome. Have a look at section\n",
      "1.2 and 2.1 of the manual to see how this is done. You do not need to install STAR or\n",
      "provide any advanced options.\n",
      "Step 1: Prepare the genome index\n",
      "If you are not already in the RNA-seq directory, please change your working directory\n",
      "to it using cd.\n",
      "Create a new directory called STAR_genome using mkdir. This will be your genome\n",
      "directory.\n",
      "Then, generate the genome index using the following parameters:\n",
      "\u2022 Number of threads: 4\n",
      "\u2022 Genome dir: The genome directory you just created.\n",
      "\u2022 Genome fasta file: The genome FASTA file (ends in .fa, contained in the folder\n",
      "genome)\n",
      "\u2022 Sjdb GTF file: The full genome annotation file from ENSEMBL (ends in .gtf,\n",
      "contained in the folder annotation)\n",
      "\u2022 Sjdb overhang: Your read length - 1 (Hint: use FastQC to check the read length\n",
      "in one of the fastq files in the data folder!)\n",
      "Step 2: Run the alignment\n",
      "Now you can align the fastq files to the genome. The commands for this are explained\n",
      "in section 3.1 of the manual.\n",
      "12\n",
      "Now align the pair of files from the 2cells sample to the genome, using the following\n",
      "parameters:\n",
      "\u2022 Number of threads: 4\n",
      "\u2022 Genome dir: STAR_genome\n",
      "\u2022 Fastq files: The two fastq files from the 2cells sample, contained in the folder\n",
      "data (Remember: this is paired-end data, so you need to provide the file names\n",
      "of both files at the same time!)\n",
      "\u2022 Add the outSAMtype parameter to generate a BAM file sorted by coordinate (see\n",
      "section 4.3)\n",
      "Questions\n",
      "1. Have a look at the log file generated by STAR called Log.final.out. How many\n",
      "reads could STAR map to the genome? How does that compare to Tophat?\n",
      "Hint: You can find mapping statistics from Tophat using samtools flagstat\n",
      "on the tophat/ZV9_2cells/accepted_hits.bam file.\n",
      "2. Can you think of a reason for the difference in number of aligned reads? How\n",
      "many initial reads does the 2cells dataset contain?\n",
      "Hint: Run the following command instead on the tophat/ZV9_2cells/accepted_hits.bam\n",
      "file:\n",
      "samtools view tophat/ZV9_2cells/accepted_hits.bam | cut -f 1 | sort -u |\n",
      "wc -l\n",
      "Bonus Exercise III\n",
      "In the transcriptome assembly part we discussed how multi-mapping might has an\n",
      "effect on the transcriptome assembly of novel transcripts. Let us re-do this part of the\n",
      "analysis using only uniquely mapped reads. During this exercise we will also learn how\n",
      "to extract splice junctions in a .BED file from a BAM file.\n",
      "\u2022 Filter the 2cells BAM file to only contain uniquely aligned reads\n",
      "13\n",
      "\u2013 Hint: use samtools view to keep only those with a mapping score equal to\n",
      "50\n",
      "\u2013 Check the samtools view manual on how to do that.\n",
      "\u2013 Store the output in a file called: 2cells_unique.bam\n",
      "\u2022 Remove duplicates from the 2cells_unique.bam file using the MarkDuplicates\n",
      "application from picard tools.\n",
      "\u2013 Hint: To call picard tools on this computer use java -jar $PICARD\n",
      "MarkDuplicates and add any options needed for the task you want to\n",
      "perform. By default this function only marks duplicates. However, what\n",
      "we want is to remove them too. Find the right option in the tool manual\n",
      "to do so.\n",
      "\u2022 Store the output in a file called 2cells_unique_rmdup.bam\n",
      "\u2022 To extract the splice junctions from the 2cells_unique_rmdup.bam follow the\n",
      "suggested solution from user brentp in this thread: https://www.biostars.org/\n",
      "p/12626/\n",
      "\u2013 Attention: In our case we start from a BAM file rather than a SAM file.\n",
      "Hence the first samtools command suggested needs to be changed so as to\n",
      "convert BAM to SAM. Keep the -h option because we also need the header\n",
      "of the file (see below why).\n",
      "\u2013 Attention: The awk command suggested in his answer should be changed\n",
      "to awk ($6 ~ /N/ || $0 ~ /^@/)\n",
      "This will ensure that you also keep the header of the BAM file, which is\n",
      "essential when you\u2019d like to convert SAM to BAM. Otherwise samtools will\n",
      "give you the following error.\n",
      "[E::sam_parse1] missing SAM header\n",
      "[W::sam_read1] parse error at line 1\n",
      "[main_samview] truncated file.\n",
      "\u2022 Run the guided Cufflinks transcriptome assembly on this new BAM file\n",
      "\u2022 Compare the two transcripts.gtf (the one from cufflinks/2cells/transcripts.gtf\n",
      "and the one you just generated) using cuffcompare.\n",
      "\u2022 Load them both on IGV and have a look at the results. Do you observe any\n",
      "differences in the transcriptome assembly around the ENSDART00000082297 transcript?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b><u>Reference Material</u></b>   \n",
      "1. Trapnell, C., Pachter, L. & Salzberg, S. L. TopHat: discovering splice junctions\n",
      "with RNA-Seq. Bioinformatics 25, 1105\u20131111 (2009).   \n",
      "2. Trapnell, C. et al. Transcript assembly and quantification by RNA-Seq reveals\n",
      "unannotated transcripts and isoform switching during cell differentiation. Nat.\n",
      "Biotechnol. 28, 511\u2013515 (2010).   \n",
      "3. Langmead, B., Trapnell, C., Pop, M. & Salzberg, S. L. Ultrafast and memoryefficient\n",
      "alignment of short DNA sequences to the human genome. Genome Biol. 10, R25 (2009).   \n",
      "4. Roberts, A., Pimentel, H., Trapnell, C. & Pachter, L. Identification of novel\n",
      "transcripts in annotated genomes using RNA-Seq. Bioinformatics 27, 2325\u20132329\n",
      "(2011).   \n",
      "5. Roberts, A., Trapnell, C., Donaghey, J., Rinn, J. L. & Pachter, L. Improving\n",
      "RNA-Seq expression estimates by correcting for fragment bias. Genome Biol. 12,\n",
      "R22 (2011).   \n",
      "6. Young MD, Wakefield MJ, Smyth GK and Oshlack A. \u201cGene ontology analysis\n",
      "for RNA-seq: accounting for selection bias.\u201d Genome Biology, 11, pp. R14 (2010).    \n",
      "7. Dobin A, et al. STAR: ultrafast universal RNA-seq aligner. Bioinformatics 29,\n",
      "15-21 (2012).   \n",
      "\n",
      " FKPM - http://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/   "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}